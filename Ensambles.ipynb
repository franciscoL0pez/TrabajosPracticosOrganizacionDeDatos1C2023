{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjquUrdmJJIg"
      },
      "source": [
        "##Librerias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j06w1QqlJLiY"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from pandas.plotting import scatter_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lUgIO9Q46RHS"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn import tree\n",
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score, recall_score, accuracy_score,f1_score#, precision_recall_curve, roc_curve,\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "from sklearn.preprocessing import (\n",
        "    MinMaxScaler,\n",
        "    OneHotEncoder\n",
        ") \n",
        "\n",
        "import warnings \n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "warnings.simplefilter(action='ignore', category=UserWarning)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OOn8nICCW6r"
      },
      "source": [
        "##Realizamos el tratamiento de las variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJJLi5enCTUS"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LDniZH_-Culx"
      },
      "outputs": [],
      "source": [
        "df_hotels_train = pd.read_csv('drive/MyDrive/hotels_train.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D3-rrHE7Cu7O"
      },
      "outputs": [],
      "source": [
        "df_hotels_train.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bwpp1z_hCvOh"
      },
      "outputs": [],
      "source": [
        "#Eliminamos las columnas de reservation_status y reservation_status_date para evitar confusiones\n",
        "df_hotels_train = df_hotels_train.drop(['reservation_status','reservation_status_date'], axis =1) #->Desmarcar al abrir el archivo\n",
        "df_hotels_train.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MnkGgXHxCvsA"
      },
      "outputs": [],
      "source": [
        "df_hotels_train['hotel'] = df_hotels_train['hotel'].astype('string')\n",
        "df_hotels_train['arrival_date_month'] = df_hotels_train['arrival_date_month'].astype('string')\n",
        "df_hotels_train['meal'] = df_hotels_train['meal'].astype('string')\n",
        "df_hotels_train['country'] = df_hotels_train['country'].astype('string')\n",
        "df_hotels_train['id'] = df_hotels_train['id'].astype('string')\n",
        "df_hotels_train['customer_type'] = df_hotels_train['customer_type'].astype('string')\n",
        "df_hotels_train['market_segment'] = df_hotels_train['market_segment'].astype('string')\n",
        "df_hotels_train['distribution_channel'] = df_hotels_train['distribution_channel'].astype('string')\n",
        "df_hotels_train['reserved_room_type'] = df_hotels_train['reserved_room_type'].astype('string')\n",
        "df_hotels_train['assigned_room_type'] = df_hotels_train['assigned_room_type'].astype('string')\n",
        "df_hotels_train['deposit_type'] = df_hotels_train['deposit_type'].astype('string')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W44Yo-SfDpJ3"
      },
      "source": [
        "Retiramos los nulos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J3nelv_nCwJe"
      },
      "outputs": [],
      "source": [
        "#Company\n",
        "df_hotels_train['company'].fillna(-9999, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lnm3sVFgDtAu"
      },
      "outputs": [],
      "source": [
        "#Agent\n",
        "df_hotels_train['agent'].fillna(-9999, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zvjsw1dBDu0u"
      },
      "outputs": [],
      "source": [
        "#Country\n",
        "df_hotels_train['country'].fillna('PRT', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q6bMvYh8Dwgx"
      },
      "outputs": [],
      "source": [
        "#Children\n",
        "df_hotels_train['children'].fillna(0, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vO6eiYGXEAxV"
      },
      "source": [
        "Analizamos los outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z9ev6iV_Ka22"
      },
      "outputs": [],
      "source": [
        "#columnas:(lead_time, stays_in_weekend_nights, stays_in_week_nights, adults, children, babies, previous_cancellations, previous_bookings_not_canceled, booking_changes, days_in_waiting_list, required_car_parking_spaces)\n",
        "media_lead_time=np.mean(df_hotels_train.lead_time)\n",
        "std_lead_time=np.std(df_hotels_train.lead_time)\n",
        "df_zscore = pd.DataFrame()\n",
        "df_zscore['z_lead_time']=(df_hotels_train.lead_time - media_lead_time)/std_lead_time\n",
        "df_zscore[df_zscore['z_lead_time']>3]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cej_pCnpECHS"
      },
      "outputs": [],
      "source": [
        "for i in range(len(df_zscore['z_lead_time'])):\n",
        "  if df_zscore.z_lead_time[i] > 3:\n",
        "    df_hotels_train.lead_time[i] = round(media_lead_time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DOGcrc26EMFE"
      },
      "outputs": [],
      "source": [
        "#Normalizamos previus cancellation\n",
        "for i in range(len(df_hotels_train.previous_cancellations)):\n",
        "  if df_hotels_train.previous_cancellations[i] > 10:\n",
        "    df_hotels_train.previous_cancellations[i] = 0 #Redondeamos a 0 ya que no tiene sentido normilazarlos sacando una media"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0E0lRltOEScJ"
      },
      "outputs": [],
      "source": [
        "media_previous_bookings_not_canceled=np.mean(df_hotels_train.previous_bookings_not_canceled)\n",
        "for i in range(len(df_hotels_train.previous_bookings_not_canceled)):\n",
        "  if df_hotels_train.previous_bookings_not_canceled[i] > 30:\n",
        "    df_hotels_train.previous_bookings_not_canceled[i] = round(media_previous_bookings_not_canceled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Srd6c_rEETU8"
      },
      "outputs": [],
      "source": [
        "#Normalizamos los valores atipicos de booking change\n",
        "for i in range(len(df_hotels_train.booking_changes)):\n",
        "  if df_hotels_train.booking_changes[i] > 10:\n",
        "    df_hotels_train.booking_changes[i] = 0 #Redondeamos a 0 ya que no tiene sentido normilazarlos sacando una media"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QdrLoqUQEXJ9"
      },
      "outputs": [],
      "source": [
        "media_days_in_waiting_list = np.mean(df_hotels_train.days_in_waiting_list)\n",
        "\n",
        "for i in range(len(df_hotels_train.days_in_waiting_list)):\n",
        "  if df_hotels_train.days_in_waiting_list[i] > 100:\n",
        "    df_hotels_train.days_in_waiting_list[i] = round(media_days_in_waiting_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M46EN1VPEZ0n"
      },
      "outputs": [],
      "source": [
        "media_required_car_parking_spaces = np.mean(df_hotels_train.required_car_parking_spaces)\n",
        "\n",
        "for i in range(len(df_hotels_train.required_car_parking_spaces)):\n",
        "  if df_hotels_train.required_car_parking_spaces[i] > 7:\n",
        "    df_hotels_train.required_car_parking_spaces[i] = round(media_required_car_parking_spaces)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b81_ya2DEmz7"
      },
      "outputs": [],
      "source": [
        "\n",
        "df_hotels_train.reset_index(drop=True, inplace=True)\n",
        "for i in range(len(df_hotels_train)):\n",
        "  if df_hotels_train.adults[i] == 0:\n",
        "    df_hotels_train = df_hotels_train.drop(index = [i])\n",
        "\n",
        "df_hotels_train.reset_index(drop=True, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mWK1RzFJEoI9"
      },
      "outputs": [],
      "source": [
        "df_hotels_train.reset_index(drop=True, inplace=True)\n",
        "for i in range(len(df_hotels_train)):\n",
        "  if df_hotels_train.adults[i] <= 2 and df_hotels_train.babies[i] >= 8:\n",
        "    df_hotels_train = df_hotels_train.drop(index = [i])\n",
        "    \n",
        "\n",
        "df_hotels_train.reset_index(drop=True, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UZjV3q36EolQ"
      },
      "outputs": [],
      "source": [
        "media_adults=np.mean(df_hotels_train.adults)\n",
        "\n",
        "for i in range(len(df_hotels_train)):\n",
        "  if df_hotels_train.adults[i] >= 25:\n",
        "    df_hotels_train.adults[i] = round(media_adults)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IuPJ_YGBHlpx"
      },
      "outputs": [],
      "source": [
        "df_hotels_train.reset_index(drop=True, inplace=True)\n",
        "\n",
        "for i in range(len(df_hotels_train)):\n",
        "  if df_hotels_train.stays_in_week_nights[i] == 0 and df_hotels_train.stays_in_weekend_nights[i] == 0:\n",
        "    df_hotels_train = df_hotels_train.drop(index = [i])\n",
        "\n",
        "df_hotels_train.reset_index(drop=True, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FDsjQFAEyb2"
      },
      "source": [
        "Eliminamos id (recordar que la vamos a necesitar mas tarde)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uy1F1_oHE1yh"
      },
      "outputs": [],
      "source": [
        "eliminar_columnas = ['id'] # -> Recordar que el id lo vamos a necesitar para machear en kaggle\n",
        "                                                                      \n",
        "df_hotels_train.drop(eliminar_columnas, axis='columns', inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPl9Pd2oFGFz"
      },
      "source": [
        "## Realizamos un encode de las variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L2xs9NYdFI_w"
      },
      "outputs": [],
      "source": [
        "# Realizamos el one hot encoding, con scikit learn.\n",
        "# Por cada columna a encodear, hacer un fit transform. Dropear la columna, y agregar las columnas nuevas con el nombre adecuado\n",
        "df_hotels_train_to_encode = df_hotels_train.copy()\n",
        "cols_a_encodear = ['hotel','arrival_date_month','customer_type','meal', 'distribution_channel','market_segment', 'reserved_room_type', 'assigned_room_type', 'deposit_type', 'country']\n",
        "ohe = OneHotEncoder(drop='first', handle_unknown='infrequent_if_exist') # Siempre se elimina la primera columna, o el feature entero si solo tiene un valor (no aporta informacion).\n",
        "transformer = make_column_transformer(\n",
        "    (ohe, cols_a_encodear),\n",
        "    remainder='passthrough',\n",
        "    verbose_feature_names_out=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3jmf4GM3FN2e"
      },
      "outputs": [],
      "source": [
        "df_target = df_hotels_train['is_canceled']\n",
        "hotels_train_encoded = transformer.fit_transform(df_hotels_train_to_encode.drop('is_canceled', axis=1)) # Se dropea is_canceled, porque no hace falta encodearlo, y ademas la instancia de test no va a tener esa columna."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BLljnI_iFPiv"
      },
      "outputs": [],
      "source": [
        "df_hotels_train_encoded = pd.DataFrame(\n",
        "    hotels_train_encoded.toarray(), \n",
        "    columns=transformer.get_feature_names_out()\n",
        ")\n",
        "\n",
        "#Mostramos las primera 10 columnas de country, ya que el resto tiene una cantidad bajisima de datos y no aportan demasiado\n",
        "country_cols = df_hotels_train_encoded.columns[df_hotels_train_encoded.columns.str.startswith('country_')]\n",
        "selected_columns = (df_hotels_train_encoded[country_cols] != 0).sum()\n",
        "top_cols = selected_columns.nlargest(10).index\n",
        "other_countries = [col for col in country_cols if col not in top_cols]\n",
        "df_hotels_train_encoded['country_other'] = df_hotels_train_encoded[other_countries].sum(axis=1)\n",
        "df_hotels_train_encoded.drop(other_countries, axis=1, inplace=True)   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56C8mtxNJcms"
      },
      "outputs": [],
      "source": [
        "df_hotels_train_encoded.head(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qylZ8PEMLa4G"
      },
      "source": [
        "##Ensambles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Lo1Cdr44obL"
      },
      "source": [
        "SVM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2XqZSbw6ZlE"
      },
      "source": [
        "Importamos las librerias para utilizar svm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YvavAihVLadM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import sklearn as sk\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.metrics import confusion_matrix, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hySdUS4d6WuE"
      },
      "outputs": [],
      "source": [
        "def metricas(y_pred,y_test):\n",
        "\n",
        "  print(classification_report(y_test,y_pred))\n",
        "  \n",
        "  cm = confusion_matrix(y_test,y_pred)\n",
        "  sns.heatmap(cm, cmap='Blues',annot=True,fmt='g')\n",
        "  plt.xlabel('Predicted')\n",
        "  plt.ylabel('True')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Antes de utilizar svm normalizaremos los datos para obtener mejores resultados"
      ],
      "metadata": {
        "id": "T4CTrQhKEy0Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Creo conjuntos de train y test\n",
        "x_train, x_test, y_train, y_test = train_test_split(df_hotels_train_encoded.values, df_target.values, test_size=0.2, random_state=0)\n",
        "\n",
        "#Normalizo para luego utiizar en nuestro modelo\n",
        "stand_scaler = preprocessing.StandardScaler()\n",
        "x_train_norm = stand_scaler.fit_transform(x_train)\n",
        "x_test_norm = stand_scaler.transform(x_test)"
      ],
      "metadata": {
        "id": "ZYcB0FSxEyYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Probamos el modelo "
      ],
      "metadata": {
        "id": "JWDFP3gCZKws"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#OBSERVACION: Esto tarda bastante en ejecutar y hasta creo que no es necesario tenerlo, pero o dejo por las dudas\n",
        "\n",
        "#Construyo un modelo SVM  \n",
        "#svm_norm = SVC()\n",
        "\n",
        "#Lo entreno con los datos escalados con normalizacion\n",
        "#svm_norm.fit(x_train_norm, y_train)\n",
        "\n",
        "#Hago la prediccion y calculo las métricas\n",
        "#y_pred_norm = svm_norm.predict(x_test_norm)\n",
        "#metricas(y_pred_norm,y_test)"
      ],
      "metadata": {
        "id": "k5utmKOQZNH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SVM - KERNELS"
      ],
      "metadata": {
        "id": "AiPlSUxTMtZo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utilizaremos el modelo radial, primero buscaremos optimizar los hiper parametros utilizando grid search para encontrar los mejores \"C\" y \"gamma\""
      ],
      "metadata": {
        "id": "tnvRsIg_RFDX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import make_scorer\n",
        "\n",
        "svc = SVC()\n",
        "params = {'C':[3,4,6,10,15,30], 'kernel':['rbf','poly'], 'gamma':[1,3,4,7,5,8,3]}\n",
        "\n",
        "#Metrica que quiero optimizar \n",
        "scorer_fn = make_scorer(sk.metrics.f1_score) \n",
        "\n",
        "\n",
        "grid_s = GridSearchCV(estimator = svc, param_grid = params, cv = 5, scoring = scorer_fn )  ) \n",
        "grid_s.fit(x_train_norm, y_train)\n",
        "\n",
        "\n",
        "\n",
        "#Mejores hiperparametros\n",
        "print(grid_s.best_params_)\n",
        "\n",
        "#Mejor métrica\n",
        "print(grid_s.best_score_)\n",
        "     "
      ],
      "metadata": {
        "id": "oXWVWB6kU4HC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez terminada la busquda de hiper parametros creamos el clasificador y mostramos la matriz de confusion"
      ],
      "metadata": {
        "id": "rMwZni-Re9Dj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Creo un clasificador con kernel radial y lo entreno sobre los datos normalizados\n",
        "\n",
        "clf = SVC(kernel='rbf', C=5, gamma=10) # -> Aca tenemos que encontrar los mejores hipers params\n",
        "clf.fit(x_train_norm, y_train)\n",
        "\n",
        "#Hago la predicción y calculo las métricas\n",
        "y_pred_rad=clf.predict(x_test_norm)\n",
        "metricas(y_pred_rad,y_test)"
      ],
      "metadata": {
        "id": "xpkA-JT_fNnH"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}